# llama-in-a-box
In case anyone needs a 'Llama in a Box' today, here's  a Docker container running Llama 3.2 using Ollama.    Remember: it's scalable, adaptable, and spits out results... and occasionally, just spits (aka it may not work).        DISCLAIMER -- this is built as a gag and not meant to be secure or production-ready


#Instructions
run "python setup.py" and follow the localhost IP address
